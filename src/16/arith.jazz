u8[256] gf16_mult_table = {
    0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00, 
    0x00,0x01,0x02,0x03,0x04,0x05,0x06,0x07,0x08,0x09,0x0a,0x0b,0x0c,0x0d,0x0e,0x0f, 
    0x00,0x02,0x04,0x06,0x08,0x0a,0x0c,0x0e,0x03,0x01,0x07,0x05,0x0b,0x09,0x0f,0x0d, 
    0x00,0x03,0x06,0x05,0x0c,0x0f,0x0a,0x09,0x0b,0x08,0x0d,0x0e,0x07,0x04,0x01,0x02, 
    0x00,0x04,0x08,0x0c,0x03,0x07,0x0b,0x0f,0x06,0x02,0x0e,0x0a,0x05,0x01,0x0d,0x09, 
    0x00,0x05,0x0a,0x0f,0x07,0x02,0x0d,0x08,0x0e,0x0b,0x04,0x01,0x09,0x0c,0x03,0x06, 
    0x00,0x06,0x0c,0x0a,0x0b,0x0d,0x07,0x01,0x05,0x03,0x09,0x0f,0x0e,0x08,0x02,0x04, 
    0x00,0x07,0x0e,0x09,0x0f,0x08,0x01,0x06,0x0d,0x0a,0x03,0x04,0x02,0x05,0x0c,0x0b, 
    0x00,0x08,0x03,0x0b,0x06,0x0e,0x05,0x0d,0x0c,0x04,0x0f,0x07,0x0a,0x02,0x09,0x01, 
    0x00,0x09,0x01,0x08,0x02,0x0b,0x03,0x0a,0x04,0x0d,0x05,0x0c,0x06,0x0f,0x07,0x0e, 
    0x00,0x0a,0x07,0x0d,0x0e,0x04,0x09,0x03,0x0f,0x05,0x08,0x02,0x01,0x0b,0x06,0x0c, 
    0x00,0x0b,0x05,0x0e,0x0a,0x01,0x0f,0x04,0x07,0x0c,0x02,0x09,0x0d,0x06,0x08,0x03, 
    0x00,0x0c,0x0b,0x07,0x05,0x09,0x0e,0x02,0x0a,0x06,0x01,0x0d,0x0f,0x03,0x04,0x08, 
    0x00,0x0d,0x09,0x04,0x01,0x0c,0x08,0x05,0x02,0x0f,0x0b,0x06,0x03,0x0e,0x0a,0x07, 
    0x00,0x0e,0x0f,0x01,0x0d,0x03,0x02,0x0c,0x09,0x07,0x06,0x08,0x04,0x0a,0x0b,0x05, 
    0x00,0x0f,0x0d,0x02,0x09,0x06,0x04,0x0b,0x01,0x0e,0x0c,0x03,0x08,0x07,0x05,0x0a
};

u8[96] __gf16_mulbase = {
        0x00,0x02,0x04,0x06,0x08,0x0a,0x0c,0x0e, 0x03,0x01,0x07,0x05,0x0b,0x09,0x0f,0x0d, 0x00,0x02,0x04,0x06,0x08,0x0a,0x0c,0x0e, 0x03,0x01,0x07,0x05,0x0b,0x09,0x0f,0x0d,
        0x00,0x04,0x08,0x0c,0x03,0x07,0x0b,0x0f, 0x06,0x02,0x0e,0x0a,0x05,0x01,0x0d,0x09, 0x00,0x04,0x08,0x0c,0x03,0x07,0x0b,0x0f, 0x06,0x02,0x0e,0x0a,0x05,0x01,0x0d,0x09,
        0x00,0x08,0x03,0x0b,0x06,0x0e,0x05,0x0d, 0x0c,0x04,0x0f,0x07,0x0a,0x02,0x09,0x01, 0x00,0x08,0x03,0x0b,0x06,0x0e,0x05,0x0d, 0x0c,0x04,0x0f,0x07,0x0a,0x02,0x09,0x01
};

// table[i] = i^{-1} mod GF(16)
u8[16] gf16_inverse_tab = {
    0, 1, 9, 14, 13, 11, 7, 6, 15, 2, 12, 5, 10, 4, 3, 8
};

export 
fn gf16_add(reg u8 a, reg u8 b) -> reg u8 {
	reg u8 c;
	c = a ^ b;
	return c;
}

export
fn gf16_sub(reg u8 a, reg u8 b) -> reg u8 {
	reg u8 c;
	c = a ^ b;
	return c;
}


export
fn gf16_mul(reg u8 a, reg u8 b) -> reg u8 {
	reg u8 r b1, r1, r2;

    // Step 1
	b1 = b;
	b1 >>= 3;
	b1 = - b1;
    r = b1 & a;


	// step 2
	b1 = b;
	b1 >>= 2;
	b1 = b1 & 1;
	b1 = - b1;
	b1 = b1 & a;

	r1 = r;
	r1 >>= 3;
	r1 = -r1;
	r1 = r1 & 0x3;

    r2 = r;
	r2 = r2 + r2;
	r2 = r2 & 0xF;

    r = r ^ r2;
	r = r ^ r1;


	// step 3
	b1 = b;
	b1 >>= 1;
	b1 = b1 & 1;
	b1 = -b1;
	b1 = b1 & a;

	r1 = r;
	r1 >>= 3;
	r1 = -r1;
	r1 = r1 & 0x3;

    r2 = r;
	r2 = r2 + r2;
	r2 = r2 & 0xF;

    r = r ^ r2;
	r = r ^ r1;


	// step 4
	b1 = b;
	b1 = b1 & 1;
	b1 = -b1;
	b1 = b1 & a;

	r1 = r;
	r1 >>= 3;
	r1 = -r1;
	r1 = r1 & 0x3;

    r2 = r;
	r2 = r2 + r2;
	r2 = r2 & 0xF;

    r = r ^ r2;
	r = r ^ r1;
	return r;
}


export
fn gf16_mul_u256(reg u256 a, reg u256 b) -> reg u256 {
	reg u256 mask2, mask3, mask4, zero ll, hl;
	reg u256 tal, tah, tml, tmh;
	reg u256 acc, ret;
	reg u256 la, lb;
	la = a;
	lb = b;

	mask2 = __gf16_mulbase.[u256 (int)  0];
	mask3 = __gf16_mulbase.[u256 (int) 32];
	mask4 = __gf16_mulbase.[u256 (int) 64];
	zero = #set0_256();	

    // step 1
	hl 	= b;
	ll 	= #VPSLL_16u16(hl, 4);
	tal = #VPSLL_16u16(la, 7);
	tah = #VPSLL_16u16(la, 3);
	tml = #VPBLENDVB_256(zero, ll, tal);
	tmh = #VPBLENDVB_256(zero, hl, tah);
	ret = tml ^ tmh;

    // step 2
	hl 	= #VPSHUFB_256(mask2, lb);
	ll 	= #VPSLL_16u16(hl, 4);
	tal = #VPSLL_16u16(la, 6);
	tah = #VPSLL_16u16(la, 2);
	tml = #VPBLENDVB_256(zero, ll, tal);
	tmh = #VPBLENDVB_256(zero, hl, tah);
	acc = tml ^ tmh;
	ret = ret ^ acc;

    // step 3
	hl 	= #VPSHUFB_256(mask2, lb);
	ll 	= #VPSLL_16u16(hl, 4);
	tal = #VPSLL_16u16(la, 5);
	tah = #VPSLL_16u16(la, 1);
	tml = #VPBLENDVB_256(zero, ll, tal);
	tmh = #VPBLENDVB_256(zero, hl, tah);
	acc = tml ^ tmh;
	ret = ret ^ acc;

    // step 4
	hl 	= #VPSHUFB_256(mask2, lb);
	ll 	= #VPSLL_16u16(hl, 4);
	tal = #VPSLL_16u16(la, 4);
	tml = #VPBLENDVB_256(zero, ll, tal);
	tmh = #VPBLENDVB_256(zero, hl, la);
	acc = tml ^ tmh;
	ret = ret ^ acc;

	return ret;
}
